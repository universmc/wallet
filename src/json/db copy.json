  {
    "models": [
      {
        "id": 1,
        "name": "Pi.ai",
        "model": "llama3.2",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 2,
        "name": "neoFs",
        "model": "llama3.2",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 3,
        "name": "worker",
        "model": "llama3.2",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 4,
        "name": "AlgoGenesis",
        "model": "llama3.2",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 5,
        "name": "Axiom",
        "model": "llama3.2",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 6,
        "name": "Gemma",
        "model": "gemma-2b-it",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },     
      {
        "id": 7,
        "name": "Avatars",
        "model": "llama3.2",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 8,
        "name": "assistant",
        "model": "llama3-8b-8192",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 8,
        "name": "assistant-instant",
        "model": "llama-3.1-8b-instant",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 9,
        "name": "assistant-preview",
        "model": "llama-3.2-3b-preview",
        "description": "Ce modèle est un autre exemple de modèle Llama",
        "temperature": 0.75,
        "max_tokens": 1024,
        "top_p": 0.8,
        "stream": true
      },
      {
        "id": 10,
        "name": "assistant-guard",
        "model": "llama-guard-3-8b",
        "description": "Ce modèle est un autre exemple de modèle Llama",
        "temperature": 0.25,
        "max_tokens": 256,
        "top_p": 0.2,
        "stream": false
      },
      {
        "id": 11,
        "name": "assistant-versatile",
        "model": "llama-3.1-70b-versatile",
        "description": "Ce modèle est un autre exemple de modèle Llama",
        "temperature": 0.25,
        "max_tokens": 256,
        "top_p": 0.2,
        "stream": false
      },
      {
        "id": 12,
        "name": "Mixtral",
        "model": "mixtral-8x7b-32768",
        "description": "Ce modèle est exemple de modèle Mixtral",
        "temperature": 0.25,
        "max_tokens": 256,
        "top_p": 0.2,
        "stream": false
      },
      {
        "id": 13,
        "name": "Gemini",
        "model": "gemma2-9b-it",
        "description": "Ce modèle est exemple de modèle Gemma",
        "temperature": 0.25,
        "max_tokens": 256,
        "top_p": 0.2,
        "stream": false
      },
      {
        "id": 14,
        "name": "claude",
        "model": "llama3.2",
        "description": "Ce modèle est un exemple de modèle ollama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 15,
        "name": "GPT",
        "model": "gpt-4o",
        "description": "Ce modèle est un exemple de modèle GPT",
        "temperature": 0.25,
        "max_tokens": 256,
        "top_p": 0.2,
        "stream": false
      },
      {
        "id": 16,
        "name": "gpt-wallet",
        "model": "gpt-3",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 17,
        "name": "Match_in_Learing",
        "model": "llama3.2",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 18,
        "name": "MandtoryAi_bot",
        "model": "llama3.2",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 19,
        "name": "Generous_Tresor",
        "model": "llama3.2",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 20,
        "name": "Gem_bot",
        "model": "llama3.2",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 21,
        "name": "facebook_Pibot",
        "model": "llama3.2",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 22,
        "name": "Youtube_Pibot",
        "model": "llama3.2",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 23,
        "name": "linkedin",
        "model": "llama3.2",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      },
      {
        "id": 24,
        "name": "Pibot",
        "model": "llama3.2",
        "description": "Ce modèle est un exemple de modèle Llama",
        "temperature": 0.5,
        "max_tokens": 512,
        "top_p": 0.5,
        "stream": false
      }
    ]
  }